{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo3_Build_CBOW.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkada/.com/blob/master/module3/Module3_Demo3_Build_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK1bATCjslcP",
        "outputId": "8ea61541-a9c6-446a-b99e-94f7f7f4632a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 19 15:44:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "id": "1xjtM8YaoYhl",
        "outputId": "0160e0db-2ff7-497f-d087-9de004377380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "kFQM_HAJgHEz",
        "outputId": "5dee644c-a13a-40ae-8a26-7b465d9041a6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c1437c1e2a72>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAG_NEWS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "import warnings\n",
        "import os\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hP5znc6NBCg",
        "outputId": "62dc36e9-19b2-4373-91a0-a2877dda174e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "7Bh1RqQUPWeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "text_df = yelp.text"
      ],
      "metadata": {
        "id": "7jcOGQHDPYP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 2500\n",
        "CORPUS_SIZE = 2000\n",
        "train_size = 50000"
      ],
      "metadata": {
        "id": "s_1umLOsgk5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbhIGLlHskQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data_iter, tokenizer):\n",
        "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(data_iter, tokenizer),\n",
        "        specials=[\"<unk>\"],\n",
        "        min_freq=10,\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n"
      ],
      "metadata": {
        "id": "LNIYzlnzhZIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sampled = text_df.sample(CORPUS_SIZE).values"
      ],
      "metadata": {
        "id": "ucls-7mkNQHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = lambda x: TextBlob(x).words\n",
        "vocab = build_vocab(text_sampled, tokenizer)\n",
        "print(f'Vocab size is {len(vocab)}')"
      ],
      "metadata": {
        "id": "0d4exCm_hyPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb175ddd-0135-487f-cff7-ba98f7c23f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is 2295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMAq5FMjVDt",
        "outputId": "074206fb-5ca0-4530-e7b5-a62226f03b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(tokenizer(\"This is a fantastic ice cream\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xau74OLTjz5z",
        "outputId": "7a9e0766-b15c-4028-a29b-a79cb9d6cd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[79, 8, 4, 384, 339, 264]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(text_sampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HK_AkCK5mSwT",
        "outputId": "ab5cf5be-3e96-47c4-9aa9-e077c53a67cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Zipps has good bar food, but the service is usually horrible. The waitresses rarely come to your table. BUT, what really rubs me the wrong way is this....\\nOn multiple occasions, when I pay the bill, the waiter doesn't bring me back the correct change. Even if my change is 1 cent, I'm entitled to receive my money back. \\nI'm sorry, but not giving me back my  change because you deem it insignificant doesn't float well with me. They do have great food though.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "word_to_ix = {}\n",
        "for sentence in text_sampled:\n",
        "  for word in tokenizer(sentence):\n",
        "    word_to_ix[word] = vocab([word])[0]"
      ],
      "metadata": {
        "id": "6y7KGL1fiMDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix_to_word = {ix:word for word, ix in word_to_ix.items()}"
      ],
      "metadata": {
        "id": "NPwMGoeyjEy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for sentence in text_sampled:\n",
        "  tokenized_sentence = tokenizer(sentence)\n",
        "  for i in range(2, len(tokenized_sentence) - 2):\n",
        "    context = [tokenized_sentence[i - 2], tokenized_sentence[i - 1],\n",
        "               tokenized_sentence[i + 1], tokenized_sentence[i + 2]]\n",
        "    target = tokenized_sentence[i]\n",
        "    data.append((context, target))"
      ],
      "metadata": {
        "id": "BCcPLFM0kqc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Lenght of input (sampled) text set is {len(data)}, reducing it to {train_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM0Znu5VP5D2",
        "outputId": "74c8420c-0e89-4289-8964-b2b1b3303492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of input (sampled) text set is 261562, reducing it to 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:train_size]"
      ],
      "metadata": {
        "id": "4wkpTaHSQIcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "Mb0CbAZ4qihA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "Ils21-oJqizc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size, EMBEDDING_DIM).to(device)"
      ],
      "metadata": {
        "id": "r9z1qVbYre9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "iBTpSE2PrhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  n_rows = 1\n",
        "  batches = 1\n",
        "  for context, target in data:\n",
        "      context_vector = make_context_vector(context, word_to_ix)\n",
        "      log_probs = model(context_vector)\n",
        "      total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]).to(device))\n",
        "      if n_rows > BATCH_SIZE:\n",
        "        print(f\"-\"*59)\n",
        "        print(f\"Epoch: {epoch}, Batch: {batches}, Loss: {total_loss}\")\n",
        "        batches += 1\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss = 0\n",
        "        n_rows = 0\n",
        "      n_rows += 1"
      ],
      "metadata": {
        "id": "mj2XomjrtOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01fa982-9c50-4df9-8c66-bc1147b4e17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 1, Loss: 21423.90625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 2, Loss: 21304.876953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 3, Loss: 21323.130859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 4, Loss: 21183.296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 5, Loss: 21090.353515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 6, Loss: 21037.068359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 7, Loss: 20893.548828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 8, Loss: 20765.15625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 9, Loss: 20837.5234375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 10, Loss: 20748.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 11, Loss: 20630.279296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 12, Loss: 20454.294921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 13, Loss: 20340.765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 14, Loss: 20410.9921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 15, Loss: 20321.45703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 16, Loss: 20274.927734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 17, Loss: 20170.09375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 18, Loss: 19929.51171875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 0, Batch: 19, Loss: 19958.58984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 1, Loss: 19751.5390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 2, Loss: 19657.62109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 3, Loss: 19722.662109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 4, Loss: 19557.447265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 5, Loss: 19505.2890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 6, Loss: 19565.421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 7, Loss: 19540.080078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 8, Loss: 19365.5625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 9, Loss: 19506.603515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 10, Loss: 19201.607421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 11, Loss: 19116.87109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 12, Loss: 19120.28125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 13, Loss: 19060.64453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 14, Loss: 19101.150390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 15, Loss: 18969.0546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 16, Loss: 18953.619140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 17, Loss: 18924.640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 18, Loss: 18633.146484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1, Batch: 19, Loss: 18654.548828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 1, Loss: 18534.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 2, Loss: 18409.708984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 3, Loss: 18475.021484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 4, Loss: 18291.357421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 5, Loss: 18254.16796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 6, Loss: 18356.712890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 7, Loss: 18436.978515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 8, Loss: 18192.3984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 9, Loss: 18397.544921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 10, Loss: 17913.0\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 11, Loss: 17862.076171875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 12, Loss: 17985.6484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 13, Loss: 17965.806640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 14, Loss: 17986.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 15, Loss: 17824.958984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 16, Loss: 17823.53125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 17, Loss: 17853.935546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 18, Loss: 17526.541015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2, Batch: 19, Loss: 17532.34765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 1, Loss: 17485.333984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 2, Loss: 17348.2734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 3, Loss: 17413.013671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 4, Loss: 17240.021484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 5, Loss: 17214.55859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 6, Loss: 17319.32421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 7, Loss: 17496.681640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 8, Loss: 17183.765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 9, Loss: 17457.052734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 10, Loss: 16851.41015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 11, Loss: 16828.34375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 12, Loss: 17026.43359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 13, Loss: 17036.224609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 14, Loss: 17054.205078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 15, Loss: 16883.4375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 16, Loss: 16881.197265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 17, Loss: 16965.36328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 18, Loss: 16624.33203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3, Batch: 19, Loss: 16610.78515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 1, Loss: 16606.3984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 2, Loss: 16483.970703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 3, Loss: 16552.734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 4, Loss: 16416.224609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 5, Loss: 16410.1484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 6, Loss: 16475.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 7, Loss: 16725.5078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 8, Loss: 16364.5087890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 9, Loss: 16699.345703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 10, Loss: 16039.875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 11, Loss: 16031.6376953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 12, Loss: 16261.1875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 13, Loss: 16285.033203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 14, Loss: 16313.94921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 15, Loss: 16146.357421875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 16, Loss: 16140.9697265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 17, Loss: 16264.0400390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 18, Loss: 15925.4296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4, Batch: 19, Loss: 15898.712890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 1, Loss: 15914.11328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 2, Loss: 15810.9521484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 3, Loss: 15882.1650390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 4, Loss: 15790.763671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 5, Loss: 15804.0595703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 6, Loss: 15810.3046875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 7, Loss: 16107.28125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 8, Loss: 15720.26953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 9, Loss: 16103.8125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 10, Loss: 15431.6611328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 11, Loss: 15433.2626953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 12, Loss: 15661.0166015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 13, Loss: 15676.001953125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 14, Loss: 15732.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 15, Loss: 15565.6845703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 16, Loss: 15569.0048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 17, Loss: 15706.2578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 18, Loss: 15378.4619140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 5, Batch: 19, Loss: 15344.140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 1, Loss: 15376.21875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 2, Loss: 15284.5078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 3, Loss: 15350.6748046875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 4, Loss: 15299.1298828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 5, Loss: 15326.708984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 6, Loss: 15279.552734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 7, Loss: 15612.5419921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 8, Loss: 15211.6689453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 9, Loss: 15628.146484375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 10, Loss: 14959.1337890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 11, Loss: 14976.125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 12, Loss: 15185.4892578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 13, Loss: 15181.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 14, Loss: 15270.03515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 15, Loss: 15105.462890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 16, Loss: 15122.408203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 17, Loss: 15254.5048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 18, Loss: 14939.9072265625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 6, Batch: 19, Loss: 14897.42578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 1, Loss: 14945.5869140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 2, Loss: 14861.65234375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 3, Loss: 14920.2216796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 4, Loss: 14896.75390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 5, Loss: 14938.158203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 6, Loss: 14847.2529296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 7, Loss: 15210.283203125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 8, Loss: 14799.162109375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 9, Loss: 15230.0\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 10, Loss: 14567.88671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 11, Loss: 14603.8544921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 12, Loss: 14791.7578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 13, Loss: 14771.794921875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 14, Loss: 14883.04296875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 15, Loss: 14724.302734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 16, Loss: 14756.7939453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 17, Loss: 14874.69140625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 18, Loss: 14573.0048828125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 7, Batch: 19, Loss: 14524.443359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 1, Loss: 14587.2705078125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 2, Loss: 14508.931640625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 3, Loss: 14559.4599609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 4, Loss: 14553.583984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 5, Loss: 14609.59765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 6, Loss: 14487.2685546875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 7, Loss: 14871.8515625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 8, Loss: 14458.34375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 9, Loss: 14891.220703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 10, Loss: 14238.552734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 11, Loss: 14291.0087890625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 12, Loss: 14460.6220703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 13, Loss: 14428.7333984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 14, Loss: 14557.1796875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 15, Loss: 14399.6884765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 16, Loss: 14450.6875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 17, Loss: 14555.3486328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 18, Loss: 14265.474609375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 8, Batch: 19, Loss: 14212.75390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 1, Loss: 14287.7666015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 2, Loss: 14212.5009765625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 3, Loss: 14255.4345703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 4, Loss: 14259.5302734375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 5, Loss: 14328.638671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 6, Loss: 14184.0595703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 7, Loss: 14582.5166015625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 8, Loss: 14172.9638671875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 9, Loss: 14600.7392578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 10, Loss: 13960.2470703125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 11, Loss: 14025.439453125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 12, Loss: 14179.083984375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 13, Loss: 14138.2255859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 14, Loss: 14280.017578125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 15, Loss: 14120.6943359375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 16, Loss: 14190.5400390625\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 17, Loss: 14283.3486328125\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 18, Loss: 14004.3505859375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 9, Batch: 19, Loss: 13948.197265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "metadata": {
        "id": "baEKAnFTt6ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8044f2-876c-435c-9bcb-633b6cdec22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding from first model layer\n",
        "embeddings = list(model.parameters())[0]\n",
        "embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# normalization\n",
        "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
        "norms = np.reshape(norms, (len(norms), 1))\n",
        "embeddings_norm = embeddings / norms\n",
        "embeddings_norm.shape"
      ],
      "metadata": {
        "id": "V3N0NXnSuzVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c230393-320f-41f8-ea9a-a451fc9b79fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2295, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_similar(word, topN=10):\n",
        "    word_vec = model.to(\"cpu\").get_word_emdedding(word).detach().numpy()[0]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
        "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
        "    topN_dict = {}\n",
        "    for sim_word_id in topN_ids:\n",
        "        sim_word = ix_to_word[sim_word_id]\n",
        "        topN_dict[sim_word] = dists[sim_word_id]\n",
        "    return topN_dict\n",
        "\n",
        "model.eval()\n",
        "for word, sim in get_top_similar(\"excellent\").items():\n",
        "    print(\"{}: {:.3f}\".format(word, sim))\n",
        "\n"
      ],
      "metadata": {
        "id": "b51uwCryuZnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0a2841-ef75-46f1-e452-67591cf7374e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Japanese: 3.070\n",
            "season: 3.068\n",
            "anywhere: 3.041\n",
            "dishes: 2.797\n",
            "nachos: 2.727\n",
            "basis: 2.715\n",
            "supposed: 2.639\n",
            "restaurant: 2.577\n",
            "affordable: 2.532\n",
            "Yelp: 2.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZouAmamvTE8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}