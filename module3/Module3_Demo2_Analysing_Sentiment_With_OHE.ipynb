{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkada/.com/blob/master/module3/Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing Sentiment"
      ],
      "metadata": {
        "id": "QlJeKdJfTPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first import everything and load the dataset"
      ],
      "metadata": {
        "id": "epE01e6NbbMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri00gAaqSzrq",
        "outputId": "4c6aff96-ed22-4879-b79f-191ee72a44dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(20,20)})\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHuUsDMlTXhM",
        "outputId": "374a5208-ea18-4372-d910-ecbcee71bc42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "Uq4-oO3KTnbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec44ea7-a9a2-4b9a-e662-40a940bab5ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-19 15:23:03--  https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8091185 (7.7M) [text/plain]\n",
            "Saving to: ‘yelp.csv’\n",
            "\n",
            "yelp.csv            100%[===================>]   7.72M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-19 15:23:04 (303 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "\n",
        "# Define X and y.\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n"
      ],
      "metadata": {
        "id": "i32aK_G6TZl9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing the train_test split and defining model"
      ],
      "metadata": {
        "id": "quWimVZjbemw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gPK5YmDMTbby"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)"
      ],
      "metadata": {
        "id": "v0LSrnpiUs8p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.Tensor(X_train_dtm.toarray()).to(device)\n",
        "X_test_tensor = torch.Tensor(X_test_dtm.toarray()).to(device)\n",
        "y_train = torch.Tensor(y_train.values).type(torch.LongTensor).to(device)\n",
        "y_test = torch.Tensor(y_test.values).type(torch.LongTensor).to(device)"
      ],
      "metadata": {
        "id": "SwdtffgTVRM0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(X_train_tensor.shape[1], 2),\n",
        "  nn.LogSoftmax(dim = 1)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Ip1U599PVXrg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X):\n",
        "  return model(X).to(device)\n",
        "\n",
        "def loss(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "def metric(y_pred, y):  # -> accuracy\n",
        "  return (1 / len(y)) * ((y_pred.argmax(dim = 1) == y).sum())\n"
      ],
      "metadata": {
        "id": "RB_PGA_7WTC5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's verify the metric makes sense"
      ],
      "metadata": {
        "id": "KMQJasS-YOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model(X_train_tensor).to(device)\n",
        "y_train_pred.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbKjRHJyWbTU",
        "outputId": "25921f4a-e002-446f-a678-43f6c4cbd1fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_train_pred.argmax(dim = 1) == y_train).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnE5Aj0WfoX",
        "outputId": "4717418b-4bb0-4672-ebbe-db88bf9fd66d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1195, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric(y_train_pred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMIbTz7mWm-v",
        "outputId": "0a201d34-3457-46f0-a56b-419fa5ccfc0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3657, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train_pred"
      ],
      "metadata": {
        "id": "JD4jGHO3YelM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The training routine"
      ],
      "metadata": {
        "id": "ROXVUovhYRWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "U80Pu2e8X3Il"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  y_pred = forward(X_train_tensor)\n",
        "  xe = loss(y_pred, y_train)\n",
        "  accuracy = metric(y_pred, y_train)\n",
        "  xe.backward()\n",
        "  if i % 100 == 0:\n",
        "    print(\"Loss: \", xe, \" Accuracy \", accuracy.data.item())\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kchBdsMYT94",
        "outputId": "3d89075b-bc3a-4a0a-ce54-aa720fb4d4c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.36566707491874695\n",
            "Loss:  tensor(0.1362, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9911260604858398\n",
            "Loss:  tensor(0.0756, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9951040744781494\n",
            "Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9963280558586121\n",
            "Loss:  tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9972460269927979\n",
            "Loss:  tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9978580474853516\n",
            "Loss:  tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9984700083732605\n",
            "Loss:  tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9984700083732605\n",
            "Loss:  tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  0.9987760186195374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = forward(X_test_tensor)\n",
        "print(f'Model accuracy is {metric(y_test_pred, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlU4QbIPYrPc",
        "outputId": "b54b3663-216a-4bc8-9d19-422f64052465"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is 0.8960880637168884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some manual validation"
      ],
      "metadata": {
        "id": "tNqRJ0wCbXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = np.array([\"This place was fantastic\"])\n",
        "vectorized_review = torch.Tensor(vect.transform(review).toarray()).to(device)"
      ],
      "metadata": {
        "id": "EgO7d2LdbYhD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = forward(vectorized_review)\n",
        "prediction.argmax(dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icVOjVFybsU-",
        "outputId": "5a5ab189-24ca-4ff7-d19b-59cdb847a7b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the model predicted correctly that the review was positive!"
      ],
      "metadata": {
        "id": "VBSc6m2LcPfk"
      }
    }
  ]
}